{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Quick Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "__[Basic Pandas](#Basic-Pandas)__\n",
    " - [Read CSV dataset](#Read-CSV-dataset)  \n",
    " - [Read Excel dataset](#Read-Excel-dataset)  \n",
    " - [Write a DataFrame to CSV](#Write-a-DataFrame-to-CSV)  \n",
    " - [Basic dataset feature info](#Basic-dataset-feature-info)  \n",
    " - [Basic dataset statistics](#Basic-dataset-statistics)  \n",
    " - [Drop missing data](#Drop-missing-data)  \n",
    " - [Replace missing data](#Replace-missing-data)  \n",
    " - [Check for NANs](#Check-for-NANs)  \n",
    " - [Drop a feature](#Drop-a-feature)  \n",
    " - [Convert object type to float](#Convert-object-type-to-float)  \n",
    " - [Convert DataFrame to Numpy array](#Convert-DataFrame-to-Numpy-array)  \n",
    " - [Get data by feature name](#Get-data-by-feature-name)  \n",
    " - [Apply a function to a DataFrame](#Apply-a-function-to-a-DataFrame)  \n",
    " - [Renaming a column](#Renaming-a-column)  \n",
    " - [Get the unique entries of a column](#Get-the-unique-entries-of-a-column)  \n",
    " - [Accessing sub-data frames](#Accessing-sub-data-frames)  \n",
    " - [DataFrame filtering rows by column values](#DataFrame-filtering-rows-by-column-values)  \n",
    " - [Copy columns to new DataFrame](#Copy-columns-to-new-DataFrame)  \n",
    " - [Sorting data](#Sorting-data)  \n",
    " - [Boolean indexing](#Boolean-indexing)\n",
    " - [Selecting values](#Selecting-values)\n",
    " - [Import multiple csv files into pandas and concatenate into one DataFrame](#Import-multiple-csv-files-into-pandas-and-concatenate-into-one-DataFrame)\n",
    " - [Reset index in a Pandas Dataframe](#Reset-index-in-a-Pandas-Dataframe)\n",
    " - [Remove duplicates in Pandas Dataframe](#Remove-duplicates-in-Pandas-Dataframe)\n",
    " - [Select rows from a DataFrame based on values in a column in pandas](#Select-rows-from-a-DataFrame-based-on-values-in-a-column-in-pandas)\n",
    " - [Pandas unique values multiple columns](#Pandas-unique-values-multiple-columns)\n",
    " \n",
    "__[Summary information about your data](#Summary-information-about-your-data)__  \n",
    "\n",
    "\n",
    "[Statistical summary of the DataFrame, with quartiles, median, etc.](#Statistical-summary-of-the-DataFrame-with-quartiles-median-etc)\n",
    "\n",
    "\n",
    "[Copy columns to new DataFrame](#Copy-columns-to-new-DataFrame)  \n",
    "[DataFrame filtering rows by column values](#DataFrame-filtering-rows-by-column-values) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Basic Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV dataset\n",
    "\n",
    "``` Python\n",
    "pd.DataFrame.from_csv(“csv_file”) \n",
    "```\n",
    "\n",
    "OR\n",
    "\n",
    "``` Python\n",
    "pd.read_csv(“csv_file”)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Excel dataset\n",
    "``` Python\n",
    "pd.read_excel(\"excel_file\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a DataFrame to CSV\n",
    "Comma separated and without the indices\n",
    "\n",
    "``` Python\n",
    "df.to_csv(\"data.csv\", sep=\",\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic dataset feature info\n",
    "``` Python\n",
    "df.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic dataset statistics\n",
    "``` Python\n",
    "print(df.describe())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the column names\n",
    "``` Python\n",
    "df.columns\n",
    "```\n",
    "Basic Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop missing data\n",
    "``` Python\n",
    "df.dropna(axis=0, how='any')\n",
    "```\n",
    "Returns object with labels on given axis omitted where alternately any or all of the data are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace missing data\n",
    "``` Python\n",
    "df.replace(to_replace=None, value=None)\n",
    "```\n",
    "replaces values given in “to_replace” with “value”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for NANs\n",
    "``` Python\n",
    "pd.isnull(object)\n",
    "```\n",
    "Detect missing values (NaN in numeric arrays, None/NaN in object arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop a feature\n",
    "``` Python\n",
    "df.drop('feature_variable_name', axis=1)\n",
    "```\n",
    "axis is either 0 for rows, 1 for columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert object type to float\n",
    "``` Python\n",
    "pd.to_numeric(df[\"feature_name\"], errors='coerce')\n",
    "```\n",
    "Convert object types to numeric to be able to perform computations (in case they are string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert column type to string or categorical \n",
    "```` Python\n",
    "df['zipcode'] = df.zipcode.astype(str)  \n",
    "#df.zipcode = df.zipcode.astype(str)  \n",
    "````\n",
    "_For converting to categorical:_  \n",
    "```` Python\n",
    "df['zipcode'] = df.zipcode.astype('category')  \n",
    "#df.zipcode = df.zipcode.astype('category')  \n",
    "````\n",
    "_Another solution is Categorical:_  \n",
    "```` Python\n",
    "df['zipcode'] = pd.Categorical(df.zipcode)  \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert DataFrame to Numpy array\n",
    "``` Python\n",
    "df.as_matrix()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get first “n” rows of a data frame\n",
    "``` Python\n",
    "df.head(n)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data by feature name\n",
    "``` Python\n",
    "df.loc[feature_name]\n",
    "```\n",
    "Operating on data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply a function to a DataFrame\n",
    "This one will multiple all values in the “height” column of the data frame by 2\n",
    "\n",
    "``` Python\n",
    "df[\"height\"].apply(lambda height: 2 * height)\n",
    "```\n",
    "OR\n",
    "\n",
    "``` Python\n",
    "def multiply(x):\n",
    "    return x * 2\n",
    "df[\"height\"].apply(multiply)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming a column\n",
    "Here we will rename the 3rd column of the data frame to be called “size”\n",
    "\n",
    "``` Python\n",
    "df.rename(columns = {df.columns[2]:'size'}, inplace=True)\n",
    "or\n",
    "df.rename(columns={'stobjid':'student_id'}, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the unique entries of a column\n",
    "Here we will get the unique entries of the column “name”\n",
    "\n",
    "``` Python\n",
    "df[\"name\"].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing sub-data frames\n",
    "Here we’ll grab a selection of the columns, “name” and “size” from the data frame\n",
    "\n",
    "``` Python\n",
    "new_df = df[[\"name\", \"size\"]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame filtering rows by column values  \n",
    "``` python\n",
    "df = df[(df['Num1'] > 3) & (df['Num2'] < 8)]\n",
    "#                        ^ & operator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy columns to new DataFrame\n",
    "``` Python\n",
    "new_df = old_df.filter(['A','B','D'], axis=1)\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting data\n",
    "``` Python \n",
    "df.sort_values(ascending = False)\n",
    "```  \n",
    "  \n",
    "If you want to sort the values of a data frame df on 2 columns named \"A\" and \"B\"\n",
    "\n",
    "``` Python \n",
    "df.sort_values([\"A\",\"B\"], inplace=True, ascending=True)  \n",
    "\n",
    "sorted_df = df.sort_values(by=['column_name'], ascending=False)\n",
    "```\n",
    "_Don't forget the \"inplace\" attribute, it will change the data frame itself if you don't want to change the data frame you can assign the new dataframe to another._\n",
    "\n",
    "``` Python \n",
    "df1=df.sort_values([\"A\",\"B\"], ascending=True)  \n",
    "```\n",
    "for more parameters check  [pandas.DataFrame.sort - pandas 0.17.1 documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean indexing\n",
    "Here we’ll filter our data column named “size” to show only values equal to 5\n",
    "\n",
    "``` Python \n",
    "df[df[\"size\"] == 5]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting values\n",
    "Select the first row of the “size” column\n",
    "\n",
    "\n",
    "``` Python \n",
    "df.loc([0], ['size'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import multiple csv files into pandas and concatenate into one DataFrame\n",
    "For a few files:\n",
    "```python\n",
    "df = pd.concat(map(pd.read_csv, ['data/d1.csv', 'data/d2.csv','data/d3.csv']))\n",
    "```\n",
    "For many files:\n",
    "``` python\n",
    "from os import listdir\n",
    "\n",
    "filepaths = [f for f in listdir(\"./data\") if f.endswith('.csv')]\n",
    "df = pd.concat(map(pd.read_csv, filepaths))\n",
    "```\n",
    "This pandas line which sets the df utilizes 3 things:\n",
    "\n",
    " - [Python's map (function, iterable)](https://docs.python.org/3.5/library/functions.html#map) sends to the function (the pd.read_csv()) the iterable (our list) which is every csv element in filepaths).  \n",
    " - Panda's [read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function reads in each CSV file as normal.  \n",
    " - Panda's [concat()](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) brings all these under one df variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset index in a Pandas Dataframe\n",
    "\n",
    "[reset_index()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html)  \n",
    "\n",
    "If you don't want it saved as a column, then do:\n",
    "  ``` Pandas\n",
    "  df = df.reset_index(drop=True)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates in Pandas Dataframe\n",
    "``` Python\n",
    "df = df.drop_duplicates()\n",
    " ```\n",
    "To remove duplicates of only one or a subset of columns\n",
    "``` Python\n",
    "df = df.sort_values('a_column_name_here', ascending=False)\n",
    "df = df.drop_duplicates(subset='a_column_name_here', keep='first')\n",
    "```\n",
    "[Drop duplicates example using Pandas](https://jamesrledoux.com/code/drop_duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select rows from a DataFrame based on values in a column in pandas\n",
    "To select rows whose column value equals a scalar, some_value, use ==:\n",
    "```` Python\n",
    "df.loc[df['column_name'] == some_value]\n",
    "````\n",
    "To select rows whose column value is in an iterable, some_values, use isin:\n",
    "```` Python\n",
    "df.loc[df['column_name'].isin(some_values)]\n",
    "```` \n",
    "Combine multiple conditions with &:\n",
    "```` Python\n",
    "df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "````\n",
    "Note the parentheses. Due to Python's operator precedence rules, & binds more tightly than <= and >=. Thus, the parentheses in the last example are necessary. Without the parentheses\n",
    "```` Python\n",
    "df['column_name'] >= A & df['column_name'] <= B\n",
    "````\n",
    "is parsed as\n",
    "```` Python\n",
    "df['column_name'] >= (A & df['column_name']) <= B\n",
    "````\n",
    "which results in a Truth value of a Series is ambiguous error.\n",
    "\n",
    "To select rows whose column value does not equal some_value, use !=:\n",
    "```` Python\n",
    "df.loc[df['column_name'] != some_value]\n",
    "````\n",
    "isin returns a boolean Series, so to select rows whose value is not in some_values, negate the boolean Series using ~:\n",
    "```` Python\n",
    "df.loc[~df['column_name'].isin(some_values)]\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas unique values multiple columns\n",
    "```` Python\n",
    "pd.unique(df[['Col1', 'Col2']].values.ravel())\n",
    "````\n",
    "\n",
    "__4 Methods to identify the unique values in 2 columns__  \n",
    "_Example_\n",
    "\n",
    "````Python\n",
    "print(pd.unique(app_limited_df[['degree_type_code','degree_type']].values.ravel('K')))  # 'K' tells ravel to order them in the sequence \n",
    "                                                                                        #  they appear in the memory\n",
    "print(pd.unique(app_limited_df[['degree_type_code','degree_type']].values.ravel()))\n",
    "print(pd.unique(app_limited_df[['degree_type_code','degree_type']].values.flatten()))\n",
    "\n",
    "print(pd.np.unique(app_limited_df[['degree_type_code','degree_type']].values))  #np.unique can be slower on larger dataset than pd.unique\n",
    "````\n",
    "_Output_\n",
    "```` text \n",
    "['10' '20' '30' '70' '60' '50' '40' 'Undergraduate' 'Graduate' 'Law'\n",
    " 'Graduate Professional' 'Medicine' 'Dentistry' 'PharmD']\n",
    "['10' 'Undergraduate' '20' 'Graduate' '30' 'Law' '70'\n",
    " 'Graduate Professional' '60' 'Medicine' '50' 'Dentistry' '40' 'PharmD']\n",
    "['10' 'Undergraduate' '20' 'Graduate' '30' 'Law' '70'\n",
    " 'Graduate Professional' '60' 'Medicine' '50' 'Dentistry' '40' 'PharmD']\n",
    "['10' '20' '30' '40' '50' '60' '70' 'Dentistry' 'Graduate'\n",
    " 'Graduate Professional' 'Law' 'Medicine' 'PharmD' 'Undergraduate']\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Summary information about your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of values in a data frame\n",
    "``` Python\n",
    "df.sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowest value of a data frame\n",
    "``` Python\n",
    "df.min()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest value\n",
    "``` Python\n",
    "df.max()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index of the lowest value\n",
    "``` Python\n",
    "df.idxmin()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index of the highest value\n",
    "``` Python\n",
    "df.idxmax()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical summary of the DataFrame with quartiles median etc\n",
    "``` Python\n",
    "df.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average values\n",
    "``` Python\n",
    "df.mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median values\n",
    "``` Python\n",
    "df.median()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between columns\n",
    "``` Python\n",
    "df.corr()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get these values for only one column, just select it like this#\n",
    "``` Python\n",
    "df[\"size\"].median()\n",
    "```\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pandas_quick_reference.ipynb to html\n",
      "[NbConvertApp] Writing 316281 bytes to pandas_quick_reference.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert  pandas_quick_reference.ipynb --to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
